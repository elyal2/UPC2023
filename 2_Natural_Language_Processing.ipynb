{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcTypdoS5fRNi64h8PkczM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elyal2/UPC2023/blob/main/2_Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZJqBb-dX2f9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to Big Data Analytics and Machine Learning with NLP and Computer Vision**\n",
        "# *Course Overview*\n",
        "Welcome to our comprehensive course on Big Data Analytics and Machine Learning, where we'll delve into the fascinating realms of Natural Language Processing (NLP) and Computer Vision. This course is designed to equip you with the essential skills and knowledge needed to analyze, interpret, and glean insights from large datasets using advanced machine learning techniques.\n",
        "\n",
        "Throughout this journey, we'll explore how machine learning can be applied to understand and process human languages and visual data, opening doors to numerous applications in various industries."
      ],
      "metadata": {
        "id": "ke1kwxtcASst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Challenges in Natural Language Processing (NLP)\n",
        "\n",
        "Natural Language Processing (NLP) is a field at the intersection of computer science, artificial intelligence, and linguistics. It involves the creation of computational algorithms to process and understand human language. NLP has many challenges due to the complexity and nuance of human language, including ambiguity, sarcasm, idioms, and the need for context understanding.\n",
        "\n",
        "## The Rise of Transformers\n",
        "\n",
        "Transformers have revolutionized the way we approach NLP tasks. They are a type of neural network architecture that, unlike previous models, are exceptionally good at handling sequences of data, such as text. Transformers are based on the mechanism of self-attention, weighting the influence of different parts of the input data.\n",
        "\n",
        "## Hugging Face\n",
        "Hugging Face is an AI research organization and company known for its pioneering work in the field of natural language processing (NLP). It has gained widespread recognition for developing and open-sourcing the transformers library, which provides a collection of state-of-the-art machine learning models, primarily focused on NLP tasks.\n",
        "\n",
        "One of the key impacts of Hugging Face's work is the facilitation of the open-source movement in the AI field. By open-sourcing their models and training frameworks, Hugging Face has cultivated a collaborative community where individuals and organizations can contribute to the advancement of NLP technologies. This collaborative approach has accelerated innovation, improved model performance, and increased the pace at which NLP models evolve.\n",
        "\n",
        "\n",
        "Moreover, Hugging Face has also contributed to the ML community through their model hub, which allows users to share and discover pre-trained models, and through active participation in research, often publishing papers and releasing datasets. Their work has also promoted the practice of fine-tuning pre-trained models for specific tasks, which has become a standard approach in NLP tasks due to its effectiveness and efficiency.\n",
        "\n",
        "### Hugging Face Transformers\n",
        "\n",
        "Hugging Face provides a powerful and easy-to-use library for implementing transformer models. The library includes pre-trained models that can be fine-tuned on a specific task, such as text classification, summarization, and question answering.\n",
        "\n",
        "The Hugging Face transformers library has democratized access to powerful NLP models like BERT, GPT-2, T5, and many others by making them available with an easy-to-use interface. This has enabled researchers, developers, and companies around the world to implement cutting-edge NLP features into their applications without the need for the deep and specialized expertise that was once required to build such models from scratch.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-eg9OvsR2l4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples of NLP Tasks\n",
        "\n",
        "In this section, we will explore some primary NLP tasks using Hugging Face transformers.\n"
      ],
      "metadata": {
        "id": "xG77nT0z61lj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Text Classification\n",
        "Text classification involves assigning categories or labels to a piece of text. We will use a pre-trained transformer and fine-tune it on a dataset for sentiment analysis.\n",
        "\n",
        "We will use: https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\n",
        "\n"
      ],
      "metadata": {
        "id": "-uTy1-7x9sUI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYHPgIHn1Y4p",
        "outputId": "07f14ca3-d4e3-4033-d6ba-0c019e251640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: POSITIVE, with score: 0.9983\n"
          ]
        }
      ],
      "source": [
        "# Example Python code for text classification\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
        "result = classifier(\"I love using transformers for NLP tasks!\")[0]\n",
        "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **pipeline** function is part of the transformers library provided by [Hugging Face](https://huggingface.co/docs), which is a popular and extensive library that offers a collection of pre-trained models for various Natural Language Processing (NLP) tasks. The library provides a high-level API for common tasks such as text classification, question answering, translation, summarization, and more.\n",
        "\n",
        "The result is usually a list with a dictionary for each piece of text analyzed. Each dictionary typically contains the keys 'label' and 'score', where 'label' is the predicted sentiment, and 'score' is the confidence level of the prediction."
      ],
      "metadata": {
        "id": "hmc6zedm7oza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarization\n",
        "Summarization aims to shorten a piece of text, distilling the most essential information. We will use a pre-trained model for summarizing a news article.\n",
        "\n",
        "We will use this model: https://huggingface.co/sshleifer/distilbart-cnn-12-6\n",
        "\n",
        "This is the text to analyze:\n",
        "\n",
        "```\n",
        "On Dec. 6, Google launched its latest artificial intelligence (AI) model, Gemini, which it claimed is the most advanced model currently available on the market — even better than the popular model developed by OpenAI, ChatGPT-4.\n",
        "\n",
        "This bold claim was treated like a challenge by community sleuths across the internet, who swiftly moved to examine the methods and benchmarks used by Google to assert Gemini’s supposed superiority and poke fun at the company’s marketing of the product.\n",
        "\n",
        "David Gull, CEO of AI-powered wellness startup Vital, told Cointelegraph that each model, be it ChatGPT-4, Llama 2, or now Gemini, has its own set of strengths and challenges.\n",
        "\n",
        "“When navigating the AI startup world, choosing the right language model is key to the success of your product. With Google’s introduction of the Gemini AI model, our LLM [large language model] options have expanded significantly.”\n",
        "Currently, OpenAI’s ChatGPT-4 model stands out with its “extensive real-world application,” along with enhanced safety measures, he added.\n",
        "\n",
        "Gull said as businesses now “dive into” Gemini, a good goal would be to “strike a balance between performance and customization” that aligns with the company’s mission and values and provides the best user experience.\n",
        "```"
      ],
      "metadata": {
        "id": "Xy7lbb-r23P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Python code for summarization\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline('summarization', model='sshleifer/distilbart-cnn-12-6')\n",
        "article = \"\"\"On Dec. 6, Google launched its latest artificial intelligence (AI) model, Gemini, which it claimed is the most advanced model currently available on the market — even better than the popular model developed by OpenAI, ChatGPT-4.\n",
        "\n",
        "This bold claim was treated like a challenge by community sleuths across the internet, who swiftly moved to examine the methods and benchmarks used by Google to assert Gemini’s supposed superiority and poke fun at the company’s marketing of the product.\n",
        "\n",
        "David Gull, CEO of AI-powered wellness startup Vital, told Cointelegraph that each model, be it ChatGPT-4, Llama 2, or now Gemini, has its own set of strengths and challenges.\n",
        "\n",
        "“When navigating the AI startup world, choosing the right language model is key to the success of your product. With Google’s introduction of the Gemini AI model, our LLM [large language model] options have expanded significantly.”\n",
        "Currently, OpenAI’s ChatGPT-4 model stands out with its “extensive real-world application,” along with enhanced safety measures, he added.\n",
        "\n",
        "Gull said as businesses now “dive into” Gemini, a good goal would be to “strike a balance between performance and customization” that aligns with the company’s mission and values and provides the best user experience.\"\"\"\n",
        "summary = summarizer(article, max_length=130, min_length=30, do_sample=False)[0]\n",
        "print(summary['summary_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7VVDU8X27Uq",
        "outputId": "c64737d4-dd64-45f3-e93e-61702b915203"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Google launched its latest artificial intelligence (AI) model, Gemini, which it claimed is the most advanced model currently available on the market . Community sleuths across the internet quickly moved to examine the methods and benchmarks used by Google to assert Gemini’s supposed superiority .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result is a list with a dictionary that includes the keys 'summary_text', which contains the generated summary of the input text."
      ],
      "metadata": {
        "id": "xs3_TwX98e1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question Answering\n",
        "Question answering models can find the answer to a question in a given context. We will use a pre-trained model to answer a question using a paragraph from Wikipedia.\n",
        "\n",
        "We will use: https://huggingface.co/distilbert-base-cased-distilled-squad"
      ],
      "metadata": {
        "id": "i5FBAEgb3qXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Python code for question answering\n",
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline('question-answering', model=\"distilbert-base-cased-distilled-squad\")\n",
        "context = \"\"\"France (French: [fʁɑ̃s] ⓘ), officially the French Republic (French: République française [ʁepyblik fʁɑ̃sɛːz]),[14] is a country located primarily in Western Europe. It also includes overseas regions and territories in the Americas and the Atlantic, Pacific and Indian oceans,[XII] giving it one of the largest discontiguous exclusive economic zones in the world. Metropolitan France shares borders with Belgium and Luxembourg to the north, Germany to the north east, Switzerland to the east, Italy and Monaco to the south east, Andorra and Spain to the south, and a maritime border with the United Kingdom to the north west. Its metropolitan area extends from the Rhine to the Atlantic Ocean and from the Mediterranean Sea to the English Channel and the North Sea. Its overseas territories include French Guiana in South America, Saint Pierre and Miquelon in the North Atlantic, the French West Indies, and many islands in Oceania and the Indian Ocean. Its eighteen integral regions (five of which are overseas) span a combined area of 643,801 km2 (248,573 sq mi) and have a total population of over 68 million as of January 2023.[5][8] France is a unitary semi-presidential republic with its capital in Paris, the country's largest city and main cultural and commercial centre; other major urban areas include Marseille, Lyon, Toulouse, Lille, Bordeaux, Strasbourg, and Nice.\"\"\"\n",
        "result = qa_pipeline(question=\"What is the capital of France?\", context=context)\n",
        "print(f\"Answer: '{result['answer']}' with score: {round(result['score'], 4)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBU8K0cA30yT",
        "outputId": "078c9020-ceee-4f2b-9514-3d38158a8c3b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 'Paris' with score: 0.9945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result is a dictionary containing the keys 'score', 'start', 'end', and 'answer', with 'score' representing the confidence of the answer, 'start' and 'end' indicating the position of the answer in the input context, and 'answer' containing the text of the answer itself."
      ],
      "metadata": {
        "id": "hfdFW1M-8jc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero-Shot Learning\n",
        "Zero-shot learning models are designed to understand and perform tasks they haven't been explicitly trained on. This is particularly valuable in scenarios where labeled data is scarce.\n",
        "\n",
        "**Zero-Shot Classification**\n",
        "We will demonstrate zero-shot classification, where the model classifies text into categories it has not seen during training.\n",
        "\n",
        "We will use: https://huggingface.co/facebook/bart-large-mnli"
      ],
      "metadata": {
        "id": "SrcNxB8j4Ohw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Python code for zero-shot classification\n",
        "from transformers import pipeline\n",
        "\n",
        "zero_shot_classifier = pipeline('zero-shot-classification', model=\"facebook/bart-large-mnli\")\n",
        "result = zero_shot_classifier(\n",
        "    \"This is a new breakthrough in NLP, allowing models to generalize to tasks not seen during training.\",\n",
        "    candidate_labels=['education', 'politics', 'business', 'technology']\n",
        ")\n",
        "print(f\"Label: {result['labels'][0]}, with score: {round(result['scores'][0], 4)}\")\n",
        "print(f\"Label: {result['labels'][1]}, with score: {round(result['scores'][1], 4)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6G5-mmr4Zo5",
        "outputId": "b741b0b4-8023-4cc0-9c14-51119916e494"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: technology, with score: 0.9717\n",
            "Label: business, with score: 0.0147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result is a dictionary containing the keys 'sequence', 'labels', and 'scores'. 'sequence' is the input text, 'labels' is the list of possible labels, and 'scores' is a list of confidence scores corresponding to each label."
      ],
      "metadata": {
        "id": "GIdBBHiK8rGj"
      }
    }
  ]
}